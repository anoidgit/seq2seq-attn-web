---
layout: page
title: About

---


OpenNMT is made and supported by <a href="http://yoon.io">Yoon Kim</a> and <a href="http://nlp.seas.harvard.edu">harvardnlp</a>.

<center>
<img width="200px" src="http://lstm.seas.harvard.edu/logo_nlp.png" />
</center>

Major source contributions also come from <a href="http://www.systransoft.com/">SYSTRAN</a>.

<center>
<img width="200px" src="http://www.systransoft.com/wp-content/themes/systran/img/common/logo.png" />
</center>

## Research

The main model is based on the paper
[Effective Approaches to Attention-based
Neural Machine Translation](http://stanford.edu/~lmthang/data/papers/emnlp15_attn.pdf),
Luong et al. EMNLP 2015.

Additional papers implemented include:

*
*


## Acknowledgments

Our implementation utilizes code from the following:

* [Andrej Karpathy's char-rnn repo](https://github.com/karpathy/char-rnn)
* [Wojciech Zaremba's lstm repo](https://github.com/wojzaremba/lstm)
* [Element rnn library](https://github.com/Element-Research/rnn)

## License

MIT

